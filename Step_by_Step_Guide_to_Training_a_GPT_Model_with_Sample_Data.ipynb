{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpStCCvnmZ7MxQRtgJvxI5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bc50af1ffa2a4483b2b5ddd4c55bec79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0b6f1a43943433dad7cd55028cd986a",
              "IPY_MODEL_fb4f280cdd844ff09b7616c47b4b7a68",
              "IPY_MODEL_834af7d412e14716b35050f71cbd60c3"
            ],
            "layout": "IPY_MODEL_32eb47b94c2c4cb1b7ff326b5e08f759"
          }
        },
        "c0b6f1a43943433dad7cd55028cd986a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2079d520c23744daacca3ad577018bee",
            "placeholder": "​",
            "style": "IPY_MODEL_05769934666e471489ec6844bd3ec71f",
            "value": "Map: 100%"
          }
        },
        "fb4f280cdd844ff09b7616c47b4b7a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6099070301334984a31d1dd97f1dfdff",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7e4ddd327dd4e81b49ee878b7a7a63f",
            "value": 5
          }
        },
        "834af7d412e14716b35050f71cbd60c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6589770ec5ad4d298a6a6cb010ec6be9",
            "placeholder": "​",
            "style": "IPY_MODEL_fc9ad99bfc0347e0b10546b8074ce6db",
            "value": " 5/5 [00:00&lt;00:00, 56.42 examples/s]"
          }
        },
        "32eb47b94c2c4cb1b7ff326b5e08f759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2079d520c23744daacca3ad577018bee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05769934666e471489ec6844bd3ec71f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6099070301334984a31d1dd97f1dfdff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7e4ddd327dd4e81b49ee878b7a7a63f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6589770ec5ad4d298a6a6cb010ec6be9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc9ad99bfc0347e0b10546b8074ce6db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/123vartika123/Fine-Tuning-GPT-Models-for-Customized-Text-Generation/blob/main/Step_by_Step_Guide_to_Training_a_GPT_Model_with_Sample_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Handle padding\n",
        "\n",
        "# Load your dataset\n",
        "dataset = load_dataset('text', data_files='sample_data.txt')\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, padding=True)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "# Data collator\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2-finetuned\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=5,  # Increase epochs\n",
        "    per_device_train_batch_size=2,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=GPT2LMHeadModel.from_pretrained(\"gpt2\"),\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the model\n",
        "trainer.save_model(\"./gpt2-finetuned\")\n",
        "tokenizer.save_pretrained(\"./gpt2-finetuned\")\n",
        "\n",
        "# Text generation\n",
        "input_text = \"Fine-tuning models\"\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "attention_mask = input_ids.ne(tokenizer.pad_token_id).long()\n",
        "\n",
        "output = trainer.model.generate(\n",
        "    input_ids,\n",
        "    attention_mask=attention_mask,\n",
        "    max_length=50,\n",
        "    num_return_sequences=1,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "# Output generated text\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228,
          "referenced_widgets": [
            "bc50af1ffa2a4483b2b5ddd4c55bec79",
            "c0b6f1a43943433dad7cd55028cd986a",
            "fb4f280cdd844ff09b7616c47b4b7a68",
            "834af7d412e14716b35050f71cbd60c3",
            "32eb47b94c2c4cb1b7ff326b5e08f759",
            "2079d520c23744daacca3ad577018bee",
            "05769934666e471489ec6844bd3ec71f",
            "6099070301334984a31d1dd97f1dfdff",
            "d7e4ddd327dd4e81b49ee878b7a7a63f",
            "6589770ec5ad4d298a6a6cb010ec6be9",
            "fc9ad99bfc0347e0b10546b8074ce6db"
          ]
        },
        "id": "fDZahoiNIJCx",
        "outputId": "0cb4b3c6-3863-4aba-e65a-5af6ef784c39"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc50af1ffa2a4483b2b5ddd4c55bec79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:58, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.186100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning models are a great way to get a better understanding of how a model is doing something.\n",
            "The best way to get a better understanding of a model is a model.\n",
            "\n",
            "The best way to get a better understanding of a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Text"
      ],
      "metadata": {
        "id": "W93PBXWGJyNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"./gpt2-finetuned\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"./gpt2-finetuned\")\n",
        "\n",
        "# Test the model with some input text\n",
        "input_text = \"Fine-tuning models\"\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "# Create an attention mask (1 for actual tokens, 0 for padding)\n",
        "attention_mask = input_ids.ne(tokenizer.pad_token_id).long()\n",
        "\n",
        "# Generate text with attention mask\n",
        "output = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    attention_mask=attention_mask,\n",
        "    max_length=50,  # Adjust length as needed\n",
        "    num_return_sequences=1,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "# Decode the generated text\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcJe5eE5IJJn",
        "outputId": "49ef4ec8-d1f5-47a5-fe92-bbef7ef9cd06"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning models can help them perform better on tasks.\n",
            "\n",
            "The new model can help them perform better on tasks. The new model can help them perform better on tasks. The new model can help them perform better on tasks. The new\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coherence Check"
      ],
      "metadata": {
        "id": "xoy94Y_eMDNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Load BERT model and tokenizer\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def get_bert_embedding(text):\n",
        "    inputs = bert_tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**inputs)\n",
        "    # Use the [CLS] token representation as the sentence embedding\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :]  # [CLS] token embedding\n",
        "    return cls_embedding.squeeze().numpy()  # Flatten to 1-D\n",
        "\n",
        "# Example reference text and generated text\n",
        "reference_text = \"Fine-tuning models can improve performance.\"\n",
        "generated_text = \"Fine-tuning models can help them perform better on tasks.\"\n",
        "\n",
        "# Compute embeddings\n",
        "ref_embedding = get_bert_embedding(reference_text)\n",
        "gen_embedding = get_bert_embedding(generated_text)\n",
        "\n",
        "# Compute cosine similarity\n",
        "similarity = 1 - cosine(ref_embedding, gen_embedding)\n",
        "print(f\"Coherence Similarity: {similarity:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFCU8Kw9MkOq",
        "outputId": "16d2b3b6-361a-404e-9705-4124bc8786be"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence Similarity: 0.9468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Relevance check"
      ],
      "metadata": {
        "id": "HyLHAiHTMqRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Initialize TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Example prompt and generated text\n",
        "prompt = \"Fine-tuning models\"\n",
        "generated_text = \"Fine-tuning models can help them perform better on tasks.\"\n",
        "\n",
        "# Vectorize the texts\n",
        "tfidf_matrix = vectorizer.fit_transform([prompt, generated_text])\n",
        "similarity_matrix = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
        "\n",
        "print(f\"Relevance Similarity: {similarity_matrix[0][0]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75rpyzxoIJPh",
        "outputId": "9afca040-542a-4b82-e5b9-6d373066e057"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relevance Similarity: 0.4222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creativity Entropy check"
      ],
      "metadata": {
        "id": "9sqG0cvzMvu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "def calculate_entropy(text):\n",
        "    tokens = text.split()\n",
        "    token_counts = Counter(tokens)\n",
        "    total_tokens = len(tokens)\n",
        "    entropy = -sum((count / total_tokens) * math.log2(count / total_tokens) for count in token_counts.values())\n",
        "    return entropy\n",
        "\n",
        "# Example generated text\n",
        "generated_text = \"Fine-tuning models can help them perform better on tasks.\"\n",
        "\n",
        "# Calculate entropy\n",
        "entropy = calculate_entropy(generated_text)\n",
        "print(f\"Creativity Entropy: {entropy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMZ286giIJRh",
        "outputId": "37f70814-4177-4d51-c52d-492b1c912313"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creativity Entropy: 3.1699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "17ffH-twIJVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LGkpTGlQIJYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p0--GWitIJbW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}